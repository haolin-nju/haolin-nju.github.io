<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/">

<link rel="stylesheet" href="./jemdoc.css" type="text/css">
<title>Hao Lin @ Alibaba Cloud</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Hao Lin @ Alibaba Cloud</h1>
</div>
<table class="imgtable"><tbody><tr><td>
<img src="Hao_Lin.jpg" alt="profile" width="160px"></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td align="left"><img src="./images/chinese_name.png" width="110px" ><br />
<font size="+2">Hao Lin</font><br><br>
R&D Engineer,<br>
<a href="https://www.aliyun.com/product/pai">Platform of Artificial Intelligence (PAI)</a>,<br>
<a href="https://www.aliyun.com/">Alibaba Cloud</a>,<br>
Hangzhou, Zhejiang, China.<br>
</td>
<!-- <td valign="top" width="179"><p align="center"><a href="https://www.nju.edu.cn/" target="_blank"><img height="120" src="./images/nju.jpg" width="100" border="0"> -->
<!-- </a></p></td> -->
</tr></tbody></table>

<br/>
<section>
    [ <a href="#Biography">Biography</a> |
    <a href="#Education">Education</a> |
    <a href="#Working Experience">Working Experience</a> |
	<a href="#Publication and Preprint">Publication and Preprint</a> |
    <a href="#Award">Award</a> |
	<a href="#Invited Talk">Invited Talk</a> |
    <a href="#Teaching Assistant">Teaching Assistant</a> |
    <a href="#Correspondence">Correspondence</a>]
</section>
<br/>

<section id="Biography">
<h2>Biography</h2>
<p>Currently, I am a R&D engineer in the Platform of Artificial Intelligence (PAI) of Alibaba Cloud Group. My research interest includes machine learning systems and reinforcement learning systems.</p>
<p>Prior to this position, I received Master degree from <a href="https://cs.nju.edu.cn/" target="_blank">Department of Computer Science and Technology</a> of <a href="https://www.nju.edu.cn/" target="_blank">Nanjing University</a> in June, 2024. My supervisor was <a href="https://cs.nju.edu.cn/lwj/" target="_blank">Professor Wu-Jun Li</a>.</p>
<p>Before that, I received B.Sc. degree from <a href="https://cs.nju.edu.cn/" target="_blank">Department of Computer Science and Technology</a> of <a href="https://www.nju.edu.cn/" target="_blank">Nanjing University</a> in June, 2021. In the same year, I was admitted to pursue my Master degree without entrance examination.</p></section>
<!-- <p><b><i>NOTICE:</i></b> <i>I'm always on the job market. Please feel free to contact me via hao.lin.msc{AT}gmail.com.</i></p> -->

<section id="Education">
	<h2>Education</h2>
	<ul>
		<p><li>Master, Nanjing University, China. <i>(09/2021 ~ 06/2024)</i></li>
		<ul>
			<li>Supervisor: <a href="https://cs.nju.edu.cn/lwj/" target="_blank">Professor Wu-Jun Li</a>.</li>
			<li>Major: Computer Science and Technology.</li>
			<li>Thesis: Automatic Parallelism Methods for Distributed Machine Learning.</li>
		</ul></p>
		<p><li>B.Sc., Nanjing University, China. <i>(09/2017 ~ 06/2021)</i></li>
		<ul>
			<li>Supervisor: <a href="https://cs.nju.edu.cn/lwj/" target="_blank">Professor Wu-Jun Li</a>.</li>
			<li>Major: Computer Science and Technology.</li>
			<li>GPA: 4.51/5.00, Rank: 11/173.</li>
		</ul>
		</p>
	</ul>
</section>

<section id="Working Experience">
	<h2>Working Experience</h2>
	<ul>
		<p><li>Platform Framework and Optimization R&D Engineer. Alibaba Cloud Group <i>(06/2024 ~ Now)</i></li>
		<ul>
			<li>Project 1: <a href="https://github.com/alibaba/ChatLearn">ChatLearn</a>, a flexible and efficient large-scale RLHF framework.</li>
			<ul>
				<li>Role: core contributor.</li>
				<li>Responsibility: integrating Mixture-of-Expert (MoE) models, developing core framework, and enhancing system quality attributes.</li>
				<li>Outcomes: <a href="https://github.com/QwenLM/Qwen1.5">Qwen2.5</a>, <a href="https://qwenlm.github.io/zh/blog/qwen2.5-max/">Qwen2.5-Max</a>, <a href="https://qwenlm.github.io/blog/qwq-32b-preview/">QwQ-32B-preview</a>, and <a href="https://qwenlm.github.io/blog/qwq-max-preview/">QwQ-Max-Preview</a></li>
			</ul>
			<li>Project 2: In-house fork from <a href="https://github.com/volcengine/veRL">veRL</a>, a reinforcement learning framework for LLMs.</li>
			<ul>
				<li>Role: core contributor.</li>
				<li>Responsibility: developing core framework and integrating the Megatron-Core backend for very large models.</li>
				<li>Outcomes: <a href="https://qwenlm.github.io/blog/qwen3/">Qwen3</a> series models</li>
			</ul>
		</ul></p>
		<p><li>Platform Framework and Optimization R&D Intern. Alibaba Cloud Group <i>(06/2023 ~ 09/2023)</i></li>
		<ul>
			<li>Project: <a href="https://github.com/alibaba/ChatLearn">ChatLearn</a>, a flexible and efficient large-scale RLHF framework.</li>
			<ul>
				<li>Role: contributor.</li>
				<li>Reponsibility: developing core framework and tuning performance.</li>
				<li>Outcomes: <a href="https://github.com/QwenLM/Qwen1.5">Qwen1.5</a> and <a href="https://qwenlm.github.io/blog/qwen2/">Qwen2</a></li>
			</ul>
		</ul></p>
		<p><li>Deep Learning Framework R&D Intern. Baidu Co., Ltd. <i>(06/2021 ~ 08/2021)</i></li>
		<ul>
			<li>Project: <a href="https://github.com/PaddlePaddle/Paddle" target="_blank">Paddle</a>, a deep learning framework.</li>
			<ul>
				<li>Role: contributor.</li>
				<li>Responsibility: developing and testing operators, accelerating C++ code compilation, and optimizing dynamic graph performance.</li>
				<li>Outcomes: related code is made public at  <a href="https://github.com/PaddlePaddle/Paddle" target="_blank">Paddle</a>.</li>
			</ul>
		</ul></p>
	</ul>
</section>

<section id="Publication and Preprint">
	<h2>Publication and Preprint</h2>
	<table class="imgtable"><tbody>
		<tr><td>
		<img src="./images/stabilizing.jpg" alt="Qwen3" width="300px">&nbsp;</td>
		<td align="left"><ul>
		<li><p>Chujie Zheng&dagger;, Kai Dang, Bowen Yu&dagger;, Mingze Li, Huiqiang Jiang, Junrong Lin, Yuqiong Liu, Hao Lin, Chencan Wu, Feng Hu, An Yang, Jingren Zhou, Junyang Lin. Stabilizing Reinforcement Learning with LLMs: Formulation and Practices. <i>CoRR abs/2512.01374</i>, 2025.
		[<a href=https://arxiv.org/pdf/2512.01374>PDF</a>]
		</p>
		</li>
		<p style="color:#5F5F5F;font-family:Calibri, sans-serif">
		We propose a new formulation for reinforcement learning with LLMs, viewing the token-level optimization objective as a first-order approximation to the true expected sequence-level reward.
		</p>
		</ul>
		</td></tr>
		<tr><td>
		<img src="./images/uniap.jpg" alt="UniAP" width="300px">&nbsp;</td>
		<td align="left"><ul>
		<li><p><b>Hao Lin</b>*, Ke Wu*, Jie Li*, Jun Li, and Wu-Jun Li&dagger;: UniAP: Unifying Inter- and Intra-Layer Automatic Parallelism by Mixed Integer Quadratic Programming, <i>Proceedings of the Computer Vision and Pattern Recognition Conference (CVPR), 2025</i>, pp. 20947-20957. <b>Award Candidate</b>.
		[<a href=https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_UniAP_Unifying_Inter-_and_Intra-Layer_Automatic_Parallelism_by_Mixed_Integer_CVPR_2025_paper.pdf>PDF</a>]
		[<a href=https://openaccess.thecvf.com/content/CVPR2025/supplemental/Lin_UniAP_Unifying_Inter-_CVPR_2025_supplemental.pdf>Supplemental</a>]
		[<a href=https://cvpr.thecvf.com/media/cvpr-2025/Slides/35353.pdf>Slide</a>]
		[<a href=https://www.youtube.com/watch?v=FDhDpiuAH5A>YouTube</a>]
		[<a href=bibtex/Lin_2025_CVPR.bibtex download="Lin_2025_CVPR.bibtex">bibtex</a>]
		</p>
		</li>
		<p style="color:#5F5F5F;font-family:Calibri, sans-serif">
		We propose an automatic parallelism framework UniAP. It utilizes MIQP to jointly optimize DP, TP, FSDP, and PP to enhance efficiency in training large models. Experimental results show that UniAP outperforms SOTA by up to 3.80x in throughput and reduces strategy optimization time by up to 107x across five Transformer-based models.
		</p>
		</ul></tr>
		<tr><td>
		<img src="./images/qwen3.jpg" alt="Qwen3" width="300px">&nbsp;</td>
		<td align="left"><ul>
		<li><p>Qwen Team&Dagger;: Qwen3 Technical Report. <i>CoRR abs/2505.09388</i>, 2025.
		[<a href=https://arxiv.org/pdf/2505.09388>PDF</a>]
		</p>
		</li>
		<p style="color:#5F5F5F;font-family:Calibri, sans-serif">
		We present Qwen3 series models, including models of both dense and Mixture-of-Expert (MoE) architectures. In Qwen3, we integrate thinking mode and non-thinking mode into a unified framework. Empirical evaluations demonstrate that Qwen3 achieves state-of-the-art results across diverse benchmarks.
		</p>
		</ul>
		</td></tr>
		<tr><td>
		<img src="./images/qwen2.5.jpg" alt="Qwen2.5" width="300px">&nbsp;</td>
		<td align="left"><ul>
		<li><p>Qwen Team&Dagger;: Qwen2.5 Technical Report, <i>CoRR abs/2412.15115</i>, 2024.
		[<a href=https://arxiv.org/pdf/2412.15115>PDF</a>]
		</p>
		</li>
		<p style="color:#5F5F5F;font-family:Calibri, sans-serif">
		We introduce Qwen2.5, a comprehensive series of large language models (LLMs). Qwen2.5 has demonstrated top-tier performance on a wide range of benchmarks. Additionally, Qwen2.5 models have been instrumental in training specialized models such as Qwen2.5-Math, Qwen2.5-Coder, QwQ, and multimodal models.
		</p>
		</ul>
		</td></tr>
	</tbody></table>
	<p>(*: equal contribution. &dagger;: corresponding author. &Dagger;: one of the contributors)</p>
</section>

<section id="Award">
	<h2>Award</h2>
	<ul>
		<li><p>南京大学优秀毕业生.&nbsp;Outstanding Graduates of Nanjing University.&nbsp;<i>(04/2024)</i></p></li>
		<li><p>南京大学优秀研究生.&nbsp;Excellent Graduate Student of Nanjing University.&nbsp;<i>(11/2023)</i></p></li>
		<li><p>学业奖学金一等奖.&nbsp;The First Prize of Academic Scholarship.&nbsp;<i>(11/2021, 11/2022, 11/2023)</i></p></li>
		<li><p>福佑奖学金.&nbsp;Fuyou Scholarship.&nbsp;<i>(12/2020)</i></p></li>
		<li><p>国家奖学金.&nbsp;National Scholarship.&nbsp;<i>(09/2019)</i></p></li>
		<li><p>南京大学优秀学生.&nbsp;Excellent Student of Nanjing University.&nbsp;<i>(12/2019)</i></p></li>
		<li><p>南京大学人民奖学金二等奖.&nbsp;The Second Prize of the People's Scholarship.&nbsp;<i>(11/2018)</i></p></li>
	</ul>
</section>


<section id="Invited Talk">
	<h2>Invited Talk</h2>
	<ul>
		<li>顶会作者读顶会, 第<a href="https://www.chaspark.com/#/live/1164655473853349888">14</a>期.&nbsp;Top Conference Authors Read Top Conferences, Episode <a href="https://www.chaspark.com/#/live/1164655473853349888">14</a>.&nbsp;<i>(07/2025)</i></li>
	</ul>
</section>


<section id="Teaching Assistant">
	<h2>Teaching Assistant</h2>
	<ul>
		<li><p>C程序设计语言.&nbsp;C Programming Language.&nbsp;(For undergraduate students, Spring 2023)</p></li>
		<li><p>数据库概论.&nbsp;Introduction to Databases.&nbsp;(For undergraduate students, Autumn 2022)</p></li>
		<li><p>程序设计基础.&nbsp;Basics of Programming.&nbsp;(For undergraduate students, Spring 2022)</p></li>
	</ul>
</section>

<section id="Correspondence">
<h2>Correspondence</h2>

<h3>E-mail Address</h3>
<p>baodong.lh{AT}alibaba-inc.com (Business)<br>
hao.lin.msc{AT}gmail.com (Private)</p>
</p>
</section>
<br/><br/>
<p align="center">
	<a href="https://github.com/haolin-nju" alt="GitHub"><img src="./images/github.svg"></a> &nbsp;
	<a href="mailto:hao.lin.msc@gmail.com" alt="Contact me"><img src="./images/email.svg"></a> &nbsp;
    <a href="wechat-id:nju-linh" alt="WeChat"><img src="./images/wechat.svg"></a>
</p>
<div id="footer">
	<foot>
		Page last modified since UTC+8
		<script>
			document.write(document.lastModified);
		</script>
	</foot>
<div id="footer-text">
</div>
</div>
</div>

<p><a href="#top">Back to Top</a></p>

</body></html>