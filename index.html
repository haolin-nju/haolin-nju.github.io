<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/">

<link rel="stylesheet" href="./jemdoc.css" type="text/css">
<title>Hao Lin @ Aliyun</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Hao Lin @ Aliyun</h1>
</div>
<table class="imgtable"><tbody><tr><td>
<img src="Hao_Lin.jpg" alt="profile" width="160px"></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td align="left"><img src="./images/chinese_name.png" width="110px" ><br />
<font size="+2">Hao Lin</font><br><br>
R&D Engineer,<br>
<a href="https://www.aliyun.com/product/bigdata/learn">Platform of Artificial Intelligence (PAI)</a>,<br>
<a href="https://cn.aliyun.com/">Aliyun Computing Co., Ltd.</a>,<br>
Hangzhou, Zhejiang, China.<br>
</td>
<!-- <td valign="top" width="179"><p align="center"><a href="https://www.nju.edu.cn/" target="_blank"><img height="120" src="./images/nju.jpg" width="100" border="0"> -->
<!-- </a></p></td> -->
</tr></tbody></table>

<br/>
<section>
    [ <a href="#Biography">Biography</a> |
    <a href="#Education">Education</a> |
    <a href="#Working Experience">Working Experience</a> |
	<a href="#Publication and Preprint">Publication and Preprint</a> |
    <a href="#Award">Award</a> |
    <a href="#Teaching Assistant">Teaching Assistant</a> |
    <a href="#Correspondence">Correspondence</a>]
</section>
<br/>

<section id="Biography">
<h2>Biography</h2>
<p>Currently, I am a R&D engineer in Aliyun Computing Co., Ltd.'s Platform of Artificial Intelligence (PAI). My research interest includes AI infrastructures, especially those for alignment tasks.</p>
<p>Prior to this position, I received Master degree from <a href="https://cs.nju.edu.cn/" target="_blank">Department of Computer Science and Technology</a> of <a href="https://www.nju.edu.cn/" target="_blank">Nanjing University</a> in June, 2024. My supervisor was <a href="https://cs.nju.edu.cn/lwj/" target="_blank">Professor Wu-Jun Li</a>.</p>
<p>Before that, I received B.Sc. degree from <a href="https://cs.nju.edu.cn/" target="_blank">Department of Computer Science and Technology</a> of <a href="https://www.nju.edu.cn/" target="_blank">Nanjing University</a> in June, 2021. In the same year, I was admitted to pursue my Master degree without entrance examination.</p></section>
<p><b><i>NOTICE:</i></b> I'm always on the job market, please feel free to contact me via hao.lin.msc{AT}gmail.com.</p>

<section id="Education">
	<h2>Education</h2>
	<ul>
		<p><li>Master, Nanjing University, China. <i>(09/2021 ~ 06/2024)</i></li>
		<ul>
			<li>Supervisor: <a href="https://cs.nju.edu.cn/lwj/" target="_blank">Professor Wu-Jun Li</a>.</li>
			<li>Major: Computer Science and Technology.</li>
			<li>Thesis: Automatic Parallelism Methods for Distributed Machine Learning.</li>
		</ul></p>
		<p><li>B.Sc., Nanjing University, China. <i>(09/2017 ~ 06/2021)</i></li>
		<ul>
			<li>Supervisor: <a href="https://cs.nju.edu.cn/lwj/" target="_blank">Professor Wu-Jun Li</a>.</li>
			<li>Major: Computer Science and Technology.</li>
			<li>GPA: 4.51/5.00, Rank: 11/173.</li>
		</ul>
		</p>
	</ul>
</section>

<section id="Working Experience">
	<h2>Working Experience</h2>
	<ul>
		<p><li>Platform Framework and Optimization R&D Engineer. Aliyun Computing Co., Ltd. <i>(06/2024 ~ Now)</i></li>
		<ul>
			<li>Project 1: <a href="https://github.com/alibaba/ChatLearn">ChatLearn</a>, a flexible and efficient large-scale RLHF framework.</li>
			<ul>
				<li>Role: core contributor.</li>
				<li>Responsibility: integrating Mixture-of-Expert (MoE) models, developing core framework, and enhancing system quality attributes.</li>
				<li>Outcomes: <a href="https://github.com/QwenLM/Qwen1.5">Qwen2.5</a>, <a href="https://qwenlm.github.io/zh/blog/qwen2.5-max/">Qwen2.5-Max</a>, <a href="https://qwenlm.github.io/blog/qwq-32b-preview/">QwQ-32B-preview</a>, and <a href="https://qwenlm.github.io/blog/qwq-max-preview/">QwQ-Max-Preview</a></li>
			</ul>
			<li>Project 2: In-house fork from <a href="https://github.com/volcengine/veRL">veRL</a>, a reinforcement learning framework for LLMs.</li>
			<ul>
				<li>Role: core contributor.</li>
				<li>Responsibility: integrating the Megatron-LM backend for very large models.</li>
				<li>Outcomes: <a href="https://qwenlm.github.io/blog/qwq-32b/">QwQ-32B</a> and <a href="https://qwenlm.github.io/blog/qwen3/">Qwen3</a></li>
			</ul>
		</ul></p>
		<p><li>Platform Framework and Optimization R&D Intern. Aliyun Computing Co., Ltd. <i>(06/2023 ~ 09/2023)</i></li>
		<ul>
			<li>Project: <a href="https://github.com/alibaba/ChatLearn">ChatLearn</a>, a flexible and efficient large-scale RLHF framework.</li>
			<ul>
				<li>Role: contributor.</li>
				<li>Reponsibility: developing core framework (such as parameter synchronization, flexible batch size generation, online parallel strategy transformation) and tuning performance.</li>
				<li>Outcomes: <a href="https://github.com/QwenLM/Qwen1.5">Qwen1.5</a> and <a href="https://qwenlm.github.io/blog/qwen2/">Qwen2</a></li>
			</ul>
		</ul></p>
		<p><li>Deep Learning Framework R&D Intern. Baidu Co., Ltd. <i>(06/2021 ~ 08/2021)</i></li>
		<ul>
			<li>Project: <a href="https://github.com/PaddlePaddle/Paddle" target="_blank">Paddle</a>, a deep learning framework.</li>
			<ul>
				<li>Role: contributor.</li>
				<li>Responsibility: developing and testing operators, accelerating C++ code compilation, and optimizing dynamic graph performance.</li>
				<li>Outcomes: related code is made public at  <a href="https://github.com/PaddlePaddle/Paddle" target="_blank">Paddle</a>.</li>
			</ul>
		</ul></p>
	</ul>
</section>

<section id="Publication and Preprint">
	<h2>Publication and Preprint</h2>
	<table class="imgtable"><tbody><tr><td>
		<img src="./images/uniap.jpg" alt="UniAP" width="300px">&nbsp;</td>
		<td align="left"><ul>
		<li><p><b>Hao Lin</b>*, Ke Wu*, Jie Li*, Jun Li, and Wu-Jun Li&dagger;: UniAP: Unifying Inter- and Intra-Layer Automatic Parallelism by Mixed Integer Quadratic Programming, <i>2025 IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR)</i>, <b>Award Candidate</b>.
		[PDF (To be released)]
		</p>
		</li>
		<p style="color:#5F5F5F;font-family:Calibri, sans-serif">
		We propose an automatic parallelism framework UniAP. It utilizes MIQP to jointly optimize DP, TP, FSDP, and PP to enhance efficiency in training large models. Experimental results show that UniAP outperforms SOTA by up to 3.80x in throughput and reduces strategy optimization time by up to 107x across five Transformer-based models.
		</p>
		</ul></tr>
		<tr><td>
		<img src="./images/qwen3.jpg" alt="Qwen3" width="300px">&nbsp;</td>
		<td align="left"><ul>
		<li><p>Qwen Team&Dagger;: Qwen3 Technical Report.
		[<a href=https://github.com/QwenLM/Qwen3/blob/main/Qwen3_Technical_Report.pdf>PDF</a>]
		</p>
		</li>
		<p style="color:#5F5F5F;font-family:Calibri, sans-serif">
		We present Qwen3 series models, including models of both dense and Mixture-of-Expert (MoE) architectures. In Qwen3, we integrate thinking mode and non-thinking mode into a unified framework. Empirical evaluations demonstrate that Qwen3 achieves state-of-the-art results across diverse benchmarks.
		</p>
		</ul>
		</td></tr>
		<tr><td>
		<img src="./images/qwen2.5.jpg" alt="Qwen2.5" width="300px">&nbsp;</td>
		<td align="left"><ul>
		<li><p>Qwen Team&Dagger;: Qwen2.5 Technical Report, <i>CoRR abs/2412.15115 (2024)</i>.
		[<a href=https://arxiv.org/pdf/2412.15115>PDF</a>]
		</p>
		</li>
		<p style="color:#5F5F5F;font-family:Calibri, sans-serif">
		We introduce Qwen2.5, a comprehensive series of large language models (LLMs). Qwen2.5 has demonstrated top-tier performance on a wide range of benchmarks. Additionally, Qwen2.5 models have been instrumental in training specialized models such as Qwen2.5-Math, Qwen2.5-Coder, QwQ, and multimodal models.
		</p>
		</ul>
		</td></tr>
	</tbody></table>
	<p>(*: equal contribution. &dagger;: corresponding author. &Dagger;: contributor)</p>
</section>

<section id="Award">
	<h2>Award</h2>
	<ul>
		<li><p>南京大学优秀毕业生.&nbsp;Outstanding Graduates of Nanjing University.&nbsp;<i>(04/2024)</i></p></li>
		<li><p>南京大学优秀研究生.&nbsp;Excellent Graduate Student of Nanjing University.&nbsp;<i>(11/2023)</i></p></li>
		<li><p>学业奖学金一等奖.&nbsp;The First Prize of Academic Scholarship.&nbsp;<i>(11/2021, 11/2022, 11/2023)</i></p></li>
		<li><p>福佑奖学金.&nbsp;Fuyou Scholarship.&nbsp;<i>(12/2020)</i></p></li>
		<li><p>国家奖学金.&nbsp;National Scholarship.&nbsp;<i>(09/2019)</i></p></li>
		<li><p>南京大学优秀学生.&nbsp;Excellent Student of Nanjing University.&nbsp;<i>(12/2019)</i></p></li>
		<li><p>南京大学人民奖学金二等奖.&nbsp;The Second Prize of the People's Scholarship.&nbsp;<i>(11/2018)</i></p></li>
	</ul>
</section>


<section id="Teaching Assistant">
	<h2>Teaching Assistant</h2>
	<ul>
		<li><p>C程序设计语言.&nbsp;C Programming Language.&nbsp;(For undergraduate students, Spring 2023)</p></li>
		<li><p>数据库概论.&nbsp;Introduction to Databases.&nbsp;(For undergraduate students, Autumn 2022)</p></li>
		<li><p>程序设计基础.&nbsp;Basics of Programming.&nbsp;(For undergraduate students, Spring 2022)</p></li>
	</ul>
</section>

<section id="Correspondence">
<h2>Correspondence</h2>

<h3>E-mail Address</h3>
<p>baodong.lh{AT}alibaba-inc.com (Business)<br>
hao.lin.msc{AT}gmail.com (Private)</p>
</p>
</section>
<br/><br/>
<p align="center">
	<a href="https://github.com/haolin-nju" alt="GitHub"><img src="./images/github.svg"></a> &nbsp;
	<a href="mailto:hao.lin.msc@gmail.com" alt="Contact me"><img src="./images/email.svg"></a> &nbsp;
    <a href="wechat-id:nju-linh" alt="WeChat"><img src="./images/wechat.svg"></a>
</p>
<div id="footer">
	<foot>
		Page last modified since UTC+8
		<script>
			document.write(document.lastModified);
		</script>
	</foot>
<div id="footer-text">
</div>
</div>
</div>

<p><a href="#top">Back to Top</a></p>

</body></html>